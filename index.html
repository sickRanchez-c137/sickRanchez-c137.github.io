<!DOCTYPE html>
<html>
<head>
  <title>Sick Ranchez</title>
</head>

<body>
  This is placeholder for my projects that I am proud of. Please visit my projects at:
  <ol>    
    <li> <a href="https://github.com/sickRanchez-c137/nios_NAND_interface">ONFI NAND Interface in NIOS Computer</a> </li>
    <p align-text="centre">This project present interfacing code for ONFI complatible NAND flash memory.</p>
    <li> <a href="https://github.com/sickRanchez-c137/InferenceInFPGA">Deep Inference in FPGA</a> </li>
    <p align-text="centre">A Deep Neural Network-inference accelerator is created in hardware. The codes for hardware is written in System Verilog. The hardware module is interfaced with NIOS computer system, thus this hardware acts as a peripheral to the computer system. The driver code to interface the hardware is written in C. Speedup compard to software is 400 times</p>
    <li> <a href="https://github.com/sickRanchez-c137/fileMute">File Mute Project</a> </li>
    <p align-text="centre">File Mute project hides the information inside the file. The initial version V1 changes the magic number of file and changes the extension of file. Encryption and password based protection is planned next in V2. V3 will implement compression.</p>
    <li> <a href="https://github.com/sickRanchez-c137/Chekov">Chekov</a> </li>
    <p align-text="centre">Chekov is a writer much like <a href="https://en.wikipedia.org/wiki/Anton_Chekhov">Anton Chekov</a>. However, Chekov can learn to write stories from any other writers as well.</p>
    <li> <a href="https://github.com/sickRanchez-c137/BreastCancerDataAnalysis">Breast Cancer Data Analysis</a> </li>
    <p align-text="centre">This is a small attempt on playing around with multiple classification methods in SiKit Learn. The data set was obtained from Kaggle.com.</p>
    <p aligh-text="centre"> Following are the different classification techniques used. </p>
    <ol>
      <li>Random Forest (Gini) </li>
      <li>Random Forest (Entropy)</li>
      <li>Multi Layer Perception (ReLU)</li>
      <li>Multi Layer Perception (tanh)</li>
      <li>Multi Layer Perception (sigmoid)</li>
      <li>SVM NuSVC</li>
      <li>SVM LinearSVC</li>
      <li>SVM SVC Linear</li>
      <li>SVM SVC RBF</li>
      <li>Gaussian Naive Bayes</li>
      <li> Decision Tree (Gini)</li>
      <li>Decision Tree (Entropy)</li>
      <li>Logistic Regression</li>
      <li>KNN</li>
    </ol>
    <p>After analyzing the accuracy of all the models, the conclusion reached are:<br/>
    <ul>
      <li>KNN with p=2 and num of neighbour at 5% of total data sets gives 98.2% accuracy</li>
      <li>Multi Layer Perceptron with tanh activation with 12 hidden layers gives 98.2% accuracy on Validation Set</li>
    </ul>
    </p>
  </ol>
</body>
</html>
